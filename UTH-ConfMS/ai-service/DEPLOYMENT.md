# AI Service Deployment Guide

## ğŸ“‹ Tá»•ng quan

HÆ°á»›ng dáº«n deploy AI Service cho UTH-ConfMS vá»›i Docker vÃ  monitoring.

## ğŸ³ Docker Deployment

### Prerequisites

- Docker vÃ  Docker Compose Ä‘Ã£ cÃ i Ä‘áº·t
- PostgreSQL 16+ Ä‘ang cháº¡y
- Redis (optional, nhÆ°ng khuyáº¿n nghá»‹)
- OpenAI API key hoáº·c Anthropic API key

### Quick Start

1. **Clone repository vÃ  navigate Ä‘áº¿n thÆ° má»¥c docker:**

```bash
cd UTH-ConfMS/docker
```

2. **Copy vÃ  cáº¥u hÃ¬nh environment variables:**

```bash
cp ai-service.env.example ../ai-service/.env
# Edit .env vÃ  thÃªm OPENAI_API_KEY
```

3. **Build vÃ  start services:**

```bash
docker-compose up -d
```

4. **Verify AI service is running:**

```bash
curl http://localhost:8001/health
```

### Environment Variables

CÃ¡c biáº¿n mÃ´i trÆ°á»ng quan trá»ng trong `.env`:

```env
# Required
OPENAI_API_KEY=your_api_key_here
DATABASE_URL=postgresql://postgres:123456@postgres:5432/confms_db
REDIS_URL=redis://redis:6379

# Optional
AI_PROVIDER=openai
MODEL_NAME=gpt-4o-mini
MAX_TOKENS=2000
```

## ğŸ¥ Health Checks

### Endpoints

- **GET /health** - Comprehensive health check
- **GET /api/v1/readiness** - Kubernetes readiness probe
- **GET /api/v1/liveness** - Kubernetes liveness probe
- **GET /api/v1/metrics** - System metrics

### Health Check Response

```json
{
  "status": "healthy",
  "timestamp": "2025-01-XXT10:30:00Z",
  "service": "ai-service",
  "version": "1.0.0",
  "checks": {
    "database": {"status": "healthy", "message": "Database connection OK"},
    "redis": {"status": "healthy", "message": "Redis connection OK"},
    "model_manager": {"status": "healthy", "provider": "openai"},
    "system": {"cpu_percent": 25.5, "memory_percent": 45.2}
  }
}
```

## ğŸ“Š Monitoring

### Metrics Endpoint

```bash
curl http://localhost:8001/api/v1/metrics
```

Returns:
- System resources (CPU, memory)
- Model provider information
- Feature flags status

### Logging

Logs Ä‘Æ°á»£c output ra stdout/stderr vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c collect bá»Ÿi Docker logging driver hoáº·c log aggregation service.

Log levels:
- `INFO`: Normal operations
- `WARNING`: Non-critical issues
- `ERROR`: Errors requiring attention

## ğŸ”§ Configuration

### Production Settings

1. **Update `application.properties` hoáº·c environment variables:**

```properties
# AI Service URL (for backend)
AI_SERVICE_URL=http://ai-service:8000
```

2. **Enable features per conference:**

```bash
# Via API
curl -X POST http://localhost:8001/api/v1/governance/features/enable \
  -H "Content-Type: application/json" \
  -d '{
    "conference_id": "123",
    "feature_name": "spell_check"
  }'
```

## ğŸš€ Kubernetes Deployment (Optional)

### Deployment YAML Example

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-service
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-service
  template:
    metadata:
      labels:
        app: ai-service
    spec:
      containers:
      - name: ai-service
        image: uth-confms/ai-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-secrets
              key: openai-api-key
        - name: DATABASE_URL
          valueFrom:
            configMapKeyRef:
              name: ai-config
              key: database-url
        livenessProbe:
          httpGet:
            path: /api/v1/liveness
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/v1/readiness
            port: 8000
          initialDelaySeconds: 20
          periodSeconds: 5
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
```

## ğŸ§ª Testing

### Run Unit Tests

```bash
cd ai-service
pytest tests/ -v
```

### Run Integration Tests

```bash
pytest tests/integration/ -v
```

### Run All Tests with Coverage

```bash
pytest --cov=src --cov-report=html
```

## ğŸ“ˆ Performance Tuning

### Embedding Caching

Embeddings Ä‘Æ°á»£c cache trong Redis vá»›i TTL 7 ngÃ y. Äá»ƒ tÄƒng performance:

1. **Increase Redis memory:**
```yaml
redis:
  command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
```

2. **Pre-compute embeddings:**
- Khi papers Ä‘Æ°á»£c submit
- Khi reviewers Ä‘Æ°á»£c invite

### Rate Limiting

Default: 100 requests per conference per hour. Adjust trong `.env`:

```env
RATE_LIMIT_PER_CONFERENCE=200
RATE_LIMIT_WINDOW_SECONDS=3600
```

## ğŸ”’ Security

### API Keys

- **Never commit API keys** to version control
- Use environment variables hoáº·c secrets management
- Rotate keys regularly

### Network Security

- AI service chá»‰ nÃªn accessible tá»« backend service
- Use internal network trong Docker/Kubernetes
- Enable HTTPS trong production

## ğŸ› Troubleshooting

### Service khÃ´ng start

1. Check logs:
```bash
docker logs uth_ai
```

2. Check health:
```bash
curl http://localhost:8001/health
```

3. Verify environment variables:
```bash
docker exec uth_ai env | grep OPENAI
```

### Database connection errors

1. Verify PostgreSQL is running:
```bash
docker ps | grep postgres
```

2. Check connection string:
```bash
docker exec uth_ai env | grep DATABASE_URL
```

### Redis connection errors

Redis lÃ  optional. Service sáº½ fallback vá» PostgreSQL náº¿u Redis khÃ´ng available.

## ğŸ“ Maintenance

### Update Dependencies

```bash
cd ai-service
pip install --upgrade -r requirements.txt
docker-compose build ai-service
docker-compose up -d ai-service
```

### Database Migrations

Migrations Ä‘Æ°á»£c handle bá»Ÿi backend service (Flyway). Äáº£m báº£o migration V10, V11, V12 Ä‘Ã£ cháº¡y.

### Backup

- Audit logs: Backup báº£ng `ai_audit_logs` regularly
- Feature flags: Backup báº£ng `ai_feature_flags`
- Email drafts: Backup báº£ng `email_drafts`

## ğŸ“ Support

Xem logs Ä‘á»ƒ troubleshoot:
```bash
docker logs -f uth_ai
```

LiÃªn há»‡ team phÃ¡t triá»ƒn náº¿u cáº§n há»— trá»£.


